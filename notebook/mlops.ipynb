{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Deployment Pipeline\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "En este notebook, iremos paso a paso por un pipeline de MLOps para construir, entrenar, implementar y monitorear un modelo de regresión XGBoost que predice la tarifa de taxi esperada usando el [dataset](https://registry.opendata.aws/nyc-tlc-trip-records-pds/) \"New York City Taxi\". Este pipeline presenta una estrategia de [implementación canaria](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/canary-deployment.html) con reversión en caso de error. La idea es poder entender cómo activar y monitorear el pipeline, inspeccionar el flujo de trabajo de entrenamiento, usar model monitor para configurar alertas y crear una implementación canary.\n",
    "\n",
    "### Contenido\n",
    "\n",
    "Este notebook contiene las siguientes secciones:\n",
    "\n",
    "1. [Data Prep](#Data-Prep)\n",
    "2. [Build](#Build)\n",
    "3. [Train Model](#Train-Model)\n",
    "4. [Deploy Dev](#Deploy-Dev)\n",
    "5. [Deploy Prod](#Deploy-Prod)\n",
    "6. [Monitor](#Monitor)\n",
    "6. [Cleanup](#Cleanup)\n",
    "\n",
    "### Arquitectura\n",
    "\n",
    "El diagrama de arquitectura a continuación muestra todo el pipeline de MLOps a un alto nivel.\n",
    "\n",
    "Usaremos la plantilla de CloudFormation proporcionada en este repositorio (`pipeline.yml`) para crear una demo en su propia cuenta de AWS. CloudFormation implementa varios recursos:\n",
    "\n",
    "![MLOps pipeline architecture](../docs/mlops-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install -qU awscli boto3 \"sagemaker>=2.1.0<3\" tqdm\n",
    "!{sys.executable} -m pip install -qU \"stepfunctions==2.0.0\"\n",
    "!{sys.executable} -m pip show sagemaker stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podría ser necesario reiniciar el kernel de Sagemaker para continuar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "En esta sección del cuaderno, descargaremos el dataset disponible públicamente como preparación para cargarlo en S3.\n",
    "\n",
    "### Descargar Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp 's3://nyc-tlc/trip data/green_tripdata_2018-02.csv' 'nyc-tlc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset en un dataframe de pandas, teniendo cuidado de parsear correctamente las fechas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parse_dates= ['lpep_dropoff_datetime', 'lpep_pickup_datetime']\n",
    "trip_df = pd.read_csv('nyc-tlc.csv', parse_dates=parse_dates)\n",
    "\n",
    "trip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data manipulation\n",
    "\n",
    "En lugar de usar las fechas y horas de recojo y llegada, usaremos estos features para calcular el tiempo total del viaje en minutos, los cuáles serám fáciles de trabajar con nuestor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df['duration_minutes'] = (trip_df['lpep_dropoff_datetime'] - trip_df['lpep_pickup_datetime']).dt.seconds/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset contiene un monton de columnas que no necesitamos, vamos a seleccionar una muestra de las columnas para nuestro modelo de ML. Mantenemos sólo `total_amount` (tarifa), `duration_minutes`, `passenger_count`, y `trip_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['total_amount', 'duration_minutes', 'passenger_count', 'trip_distance']\n",
    "data_df = trip_df[cols]\n",
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[(data_df.total_amount > 0) & (data_df.total_amount < 200) & \n",
    "                  (data_df.duration_minutes > 0) & (data_df.duration_minutes < 120) & \n",
    "                  (data_df.trip_distance > 0) & (data_df.trip_distance < 121) & \n",
    "                  (data_df.passenger_count > 0)].dropna()\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "sample_df = data_df.sample(1000)\n",
    "sns.scatterplot(data=sample_df, x='duration_minutes', y='trip_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=sample_df, x='duration_minutes', y='total_amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(data_df, test_size=0.20, random_state=42)\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.05, random_state=42)\n",
    "\n",
    "# Reset the index for our test dataframe\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('Size of\\n train: {},\\n val: {},\\n test: {} '.format(train_df.shape[0], val_df.shape[0], test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['total_amount', 'duration_minutes','passenger_count','trip_distance']\n",
    "train_df.to_csv('train.csv', index=False, header=False)\n",
    "val_df.to_csv('validation.csv', index=False, header=False)\n",
    "test_df.to_csv('test.csv', index=False, header=False)\n",
    "\n",
    "# Save test and baseline with headers\n",
    "train_df.to_csv('baseline.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# Get the session and default bucket\n",
    "session = sagemaker.session.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "# Specify data prefix and version\n",
    "prefix = 'nyc-tlc/v1'\n",
    "\n",
    "s3_train_uri = session.upload_data('train.csv', bucket, prefix + '/data/training')\n",
    "s3_val_uri = session.upload_data('validation.csv', bucket, prefix + '/data/validation')\n",
    "s3_test_uri = session.upload_data('test.csv', bucket, prefix + '/data/test')\n",
    "s3_baseline_uri = session.upload_data('baseline.csv', bucket, prefix + '/data/baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build\n",
    "\n",
    "### Trigger Build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import time\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "artifact_bucket = os.environ['ARTIFACT_BUCKET']\n",
    "pipeline_name = os.environ['PIPELINE_NAME']\n",
    "model_name = os.environ['MODEL_NAME']\n",
    "workflow_pipeline_arn = os.environ['WORKFLOW_PIPELINE_ARN']\n",
    "\n",
    "print('region: {}'.format(region))\n",
    "print('artifact bucket: {}'.format(artifact_bucket))\n",
    "print('pipeline: {}'.format(pipeline_name))\n",
    "print('model name: {}'.format(model_name))\n",
    "print('workflow: {}'.format(workflow_pipeline_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "input_data = {\n",
    "    'TrainingUri': s3_train_uri,\n",
    "    'ValidationUri': s3_val_uri,\n",
    "    'TestUri': s3_test_uri,\n",
    "    'BaselineUri': s3_baseline_uri\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'num_round': 50\n",
    "}\n",
    "\n",
    "zip_buffer = BytesIO()\n",
    "with zipfile.ZipFile(zip_buffer, 'a') as zf:\n",
    "    zf.writestr('inputData.json', json.dumps(input_data))\n",
    "    zf.writestr('hyperparameters.json', json.dumps(hyperparameters))\n",
    "zip_buffer.seek(0)\n",
    "\n",
    "data_source_key = '{}/data-source.zip'.format(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "s3.put_object(Bucket=artifact_bucket, Key=data_source_key, Body=bytearray(zip_buffer.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML('<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/codesuite/codepipeline/pipelines/{1}/view?region={0}\">Code Pipeline</a>'.format(region, pipeline_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Build Logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codepipeline = boto3.client('codepipeline')\n",
    "\n",
    "def get_pipeline_stage(pipeline_name, stage_name):\n",
    "    response = codepipeline.get_pipeline_state(name=pipeline_name)\n",
    "    for stage in response['stageStates']:\n",
    "        if stage['stageName'] == stage_name:\n",
    "            return stage\n",
    "\n",
    "# Get last execution id\n",
    "build_stage = get_pipeline_stage(pipeline_name, 'Build')    \n",
    "if not 'latestExecution' in build_stage:\n",
    "    raise(Exception('Please wait.  Build not started'))\n",
    "\n",
    "build_url = build_stage['actionStates'][0]['latestExecution']['externalExecutionUrl']\n",
    "\n",
    "# Out a link to the code build logs\n",
    "HTML('<a target=\"_blank\" href=\"{0}\">Code Build Logs</a>'.format(build_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "### Inspect Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stepfunctions.workflow import Workflow\n",
    "while True:\n",
    "    try:\n",
    "        workflow = Workflow.attach(workflow_pipeline_arn)\n",
    "        break\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)\n",
    "\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executions = workflow.list_executions()\n",
    "if not executions:\n",
    "    raise(Exception('Please wait.  Training not started'))\n",
    "    \n",
    "executions[0].render_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisamos el script de Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ../model/run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize Workflow (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%store input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import analytics\n",
    "experiment_name = 'mlops-{}'.format(model_name)\n",
    "model_analytics = analytics.ExperimentAnalytics(experiment_name=experiment_name)\n",
    "analytics_df = model_analytics.dataframe()\n",
    "\n",
    "if (analytics_df.shape[0] == 0):\n",
    "    raise(Exception('Please wait.  No training or baseline jobs'))\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100) # Increase column width to show full copmontent name\n",
    "cols = ['TrialComponentName', 'DisplayName', 'SageMaker.InstanceType', \n",
    "        'train:rmse - Last', 'validation:rmse - Last'] # return the last rmse for training and validation\n",
    "analytics_df[analytics_df.columns & cols].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Dev\n",
    "\n",
    "### Test Dev Deployment\n",
    "Primero, ejecutamos la celda a continuación para buscar el nombre del SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codepipeline = boto3.client('codepipeline')\n",
    "\n",
    "deploy_dev = get_pipeline_stage(pipeline_name, 'DeployDev')\n",
    "if not 'latestExecution' in deploy_dev:\n",
    "    raise(Exception('Please wait.  Deploy dev not started'))\n",
    "    \n",
    "execution_id = deploy_dev['latestExecution']['pipelineExecutionId']\n",
    "dev_endpoint_name = 'mlops-{}-dev-{}'.format(model_name, execution_id)\n",
    "\n",
    "print('endpoint name: {}'.format(dev_endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        response = sm.describe_endpoint(EndpointName=dev_endpoint_name)\n",
    "        print(\"Endpoint status: {}\".format(response['EndpointStatus']))\n",
    "        if response['EndpointStatus'] == 'InService':\n",
    "            break\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    # Support SageMaker v2 SDK: https://sagemaker.readthedocs.io/en/stable/v2.html\n",
    "    from sagemaker.predictor import Predictor\n",
    "    from sagemaker.serializers import CSVSerializer\n",
    "    def get_predictor(endpoint_name):\n",
    "        xgb_predictor = Predictor(endpoint_name)\n",
    "        xgb_predictor.serializer = CSVSerializer()\n",
    "        return xgb_predictor\n",
    "except:\n",
    "    # Fallback to SageMaker v1.70 SDK\n",
    "    from sagemaker.predictor import RealTimePredictor, csv_serializer\n",
    "    def get_predictor(endpoint_name):\n",
    "        xgb_predictor = RealTimePredictor(endpoint_name)\n",
    "        xgb_predictor.content_type = 'text/csv'\n",
    "        xgb_predictor.serializer = csv_serializer\n",
    "        return xgb_predictor\n",
    "\n",
    "def predict(predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, round(data.shape[0] / float(rows)))\n",
    "    predictions = ''\n",
    "    for array in tqdm(split_array):\n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_predictor = get_predictor(dev_endpoint_name)\n",
    "predictions = predict(dev_predictor, test_df[test_df.columns[1:]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'total_amount_predictions': predictions })\n",
    "pred_df = test_df.join(pred_df) # Join on all\n",
    "pred_df['error'] = abs(pred_df['total_amount']-pred_df['total_amount_predictions'])\n",
    "\n",
    "pred_df.sort_values('error', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=pred_df, x='total_amount_predictions', y='total_amount', hue='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(pred_df):\n",
    "    return sqrt(mean_squared_error(pred_df['total_amount'], pred_df['total_amount_predictions']))\n",
    "\n",
    "print('RMSE: {}'.format(rmse(pred_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Prod\n",
    "\n",
    "### Approve Deployment to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "def on_click(obj):\n",
    "    result = { 'summary': approval_text.value, 'status': obj.description }\n",
    "    response = codepipeline.put_approval_result(\n",
    "      pipelineName=pipeline_name,\n",
    "      stageName='DeployDev',\n",
    "      actionName='ApproveDeploy',\n",
    "      result=result,\n",
    "      token=approval_action['token']\n",
    "    )\n",
    "    button_box.close()\n",
    "    print(result)\n",
    "    \n",
    "# Create the widget if we are ready for approval\n",
    "deploy_dev = get_pipeline_stage(pipeline_name, 'DeployDev')\n",
    "if not 'latestExecution' in deploy_dev['actionStates'][-1]:\n",
    "    raise(Exception('Please wait.  Deploy dev not complete'))\n",
    "\n",
    "approval_action = deploy_dev['actionStates'][-1]['latestExecution']\n",
    "if approval_action['status'] == 'Succeeded':\n",
    "    print('Dev approved: {}'.format(approval_action['summary']))\n",
    "elif 'token' in approval_action:\n",
    "    approval_text = widgets.Text(placeholder='Optional approval message')   \n",
    "    approve_btn = widgets.Button(description=\"Approved\", button_style='success', icon='check')\n",
    "    reject_btn = widgets.Button(description=\"Rejected\", button_style='danger', icon='close')\n",
    "    approve_btn.on_click(on_click)\n",
    "    reject_btn.on_click(on_click)\n",
    "    button_box = widgets.HBox([approval_text, approve_btn, reject_btn])\n",
    "    display(button_box)\n",
    "else:\n",
    "    raise(Exception('Please wait. No dev approval'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Production Deployment\n",
    "\n",
    "\n",
    "Este paso del pipeline utiliza CloudFormation para implementar una serie de recursos. En resumen, crearemos:\n",
    "\n",
    "![Components of production deployment](../docs/cloud-formation.png)\n",
    "\n",
    "Veamos cómo avanza la implementación. Utilizamos el siguiente código para obtener el ID de ejecución del paso de implementación. Luego, generamos una tabla que enumere los recursos creados por el stack de CloudFormation y su estado de creación. Se puede volver a ejecutar la celda después de unos minutos para ver cómo avanzan los pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_prd = get_pipeline_stage(pipeline_name, 'DeployPrd')\n",
    "if not 'latestExecution' in deploy_prd or not 'latestExecution' in deploy_prd['actionStates'][0]:\n",
    "    raise(Exception('Please wait.  Deploy prd not started'))\n",
    "    \n",
    "execution_id = deploy_prd['latestExecution']['pipelineExecutionId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "def get_event_dataframe(events):\n",
    "    stack_cols = ['LogicalResourceId', 'ResourceStatus', 'ResourceStatusReason', 'Timestamp']\n",
    "    stack_event_df = pd.DataFrame(events)[stack_cols].fillna('')\n",
    "    stack_event_df['TimeAgo'] = (datetime.now(tzlocal())-stack_event_df['Timestamp'])\n",
    "    return stack_event_df.drop('Timestamp', axis=1)\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "stack_name = stack_name='{}-deploy-prd'.format(pipeline_name)\n",
    "print('stack name: {}'.format(stack_name))\n",
    "\n",
    "# Get latest stack events\n",
    "while True:\n",
    "    try:\n",
    "        response = cfn.describe_stack_events(StackName=stack_name)\n",
    "        break\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)\n",
    "    \n",
    "get_event_dataframe(response['StackEvents']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ../api/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ../api/pre_traffic_hook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ../api/post_traffic_hook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_endpoint_name='mlops-{}-prd-{}'.format(model_name, execution_id)\n",
    "print('prod endpoint: {}'.format(prd_endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        response = sm.describe_endpoint(EndpointName=prd_endpoint_name)\n",
    "        print(\"Endpoint status: {}\".format(response['EndpointStatus']))\n",
    "        # Wait until the endpoint is in service with data capture enabled\n",
    "        if response['EndpointStatus'] == 'InService' \\\n",
    "            and 'DataCaptureConfig' in response \\\n",
    "            and response['DataCaptureConfig']['EnableCapture']:\n",
    "            break\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_predictor = get_predictor(prd_endpoint_name)\n",
    "sample_values = test_df[test_df.columns[1:]].sample(100).values\n",
    "predictions = predict(prd_predictor, sample_values, rows=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test REST API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML('<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/lambda/home?region={0}#/applications/{1}-deploy-prd?tab=deploy\">Lambda Deployment</a>'.format(region, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el siguiente código para confirmar que el punto final está en servicio. Se completará una vez que la API REST esté disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_status(stack_name):\n",
    "    response = cfn.describe_stacks(StackName=stack_name)\n",
    "    if response['Stacks']:\n",
    "        stack = response['Stacks'][0]\n",
    "        outputs = None\n",
    "        if 'Outputs' in stack:\n",
    "            outputs = dict([(o['OutputKey'], o['OutputValue']) for o in stack['Outputs']])\n",
    "        return stack['StackStatus'], outputs \n",
    "\n",
    "outputs = None\n",
    "while True:\n",
    "    try:\n",
    "        status, outputs = get_stack_status(stack_name)\n",
    "        response = sm.describe_endpoint(EndpointName=prd_endpoint_name)\n",
    "        print(\"Endpoint status: {}\".format(response['EndpointStatus']))\n",
    "        if outputs:\n",
    "            break\n",
    "        elif status.endswith('FAILED'):\n",
    "            raise(Exception('Stack status: {}'.format(status)))\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)\n",
    "\n",
    "if outputs:\n",
    "    print('deployment application: {}'.format(outputs['DeploymentApplication']))\n",
    "    print('rest api: {}'.format(outputs['RestApi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/codesuite/codedeploy/applications/{1}?region={0}\">CodeDeploy application</a>'.format(region, outputs['DeploymentApplication']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CodeDeploy realizará una implementación canary y enviará el 10% del tráfico al nuevo endpoint durante un período de 5 minutos.\n",
    "\n",
    "![Traffic shift between endpoints](../docs/code-deploy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "headers = {\"Content-type\": \"text/csv\"}\n",
    "payload = test_df[test_df.columns[1:]].head(1).to_csv(header=False, index=False).encode('utf-8')\n",
    "rest_api = outputs['RestApi']\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        resp = request.urlopen(request.Request(rest_api, data=payload, headers=headers))\n",
    "        print(\"Response code: %d: endpoint: %s\" % (resp.getcode(), resp.getheader('x-sagemaker-endpoint')))\n",
    "        status, outputs = get_stack_status(stack_name) \n",
    "        if status.endswith('COMPLETE'):\n",
    "            print('Deployment complete\\n')\n",
    "            break\n",
    "        elif status.endswith('FAILED'):\n",
    "            raise(Exception('Stack status: {}'.format(status)))\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor\n",
    "\n",
    "### Inspect Model Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_prd = get_pipeline_stage(pipeline_name, 'DeployPrd')\n",
    "if not 'latestExecution' in deploy_prd:\n",
    "    raise(Exception('Please wait.  Deploy prod not complete'))\n",
    "    \n",
    "execution_id = deploy_prd['latestExecution']['pipelineExecutionId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_name='mlops-{}-pbl-{}'.format(model_name, execution_id)\n",
    "schedule_name='mlops-{}-pms'.format(model_name)\n",
    "\n",
    "print('processing job name: {}'.format(processing_job_name))\n",
    "print('schedule name: {}'.format(schedule_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.model_monitor import BaseliningJob, MonitoringExecution\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "baseline_job = BaseliningJob.from_processing_name(sagemaker_session, processing_job_name)\n",
    "status = baseline_job.describe()['ProcessingJobStatus']\n",
    "if status != 'Completed':\n",
    "    raise(Exception('Please wait. Processing job not complete, status: {}'.format(status)))\n",
    "    \n",
    "baseline_results_uri  = baseline_job.outputs[0].destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "baseline_statistics = baseline_job.baseline_statistics().body_dict\n",
    "schema_df = pd.json_normalize(baseline_statistics[\"features\"])\n",
    "schema_df[[\"name\", \"numerical_statistics.mean\", \"numerical_statistics.std_dev\",\n",
    "           \"numerical_statistics.min\", \"numerical_statistics.max\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_constraints = baseline_job.suggested_constraints().body_dict\n",
    "constraints_df = pd.json_normalize(baseline_constraints[\"features\"])\n",
    "constraints_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View data capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "data_capture_logs_uri = 's3://{}/{}/datacapture/{}'.format(bucket, model_name, prd_endpoint_name)\n",
    "\n",
    "capture_files = S3Downloader.list(data_capture_logs_uri)\n",
    "print('Found {} files'.format(len(capture_files)))\n",
    "\n",
    "if capture_files:\n",
    "    # Get the first line of the most recent file    \n",
    "    event = json.loads(S3Downloader.read_file(capture_files[-1]).split('\\n')[0])\n",
    "    print('\\nLast file:\\n{}'.format(json.dumps(event, indent=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View monitoring schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O utils.py --quiet https://raw.githubusercontent.com/awslabs/amazon-sagemaker-examples/master/sagemaker_model_monitor/visualization/utils.py\n",
    "import utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "response = sm.describe_monitoring_schedule(MonitoringScheduleName=schedule_name)\n",
    "print('Schedule Status: {}'.format(response['MonitoringScheduleStatus']))\n",
    "\n",
    "now = datetime.now(tzlocal())\n",
    "next_hour = (now+timedelta(hours=1)).replace(minute=0)\n",
    "scheduled_diff = (next_hour-now).seconds//60\n",
    "print('Next schedule in {} minutes'.format(scheduled_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../assets/deploy-model-prd.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_arn = None\n",
    "\n",
    "while processing_job_arn == None:\n",
    "    try:\n",
    "        response = sm.list_monitoring_executions(MonitoringScheduleName=schedule_name)\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    for mon in response['MonitoringExecutionSummaries']:\n",
    "        status = mon['MonitoringExecutionStatus']\n",
    "        now = datetime.now(tzlocal())\n",
    "        created_diff = (now-mon['CreationTime']).seconds//60\n",
    "        print('Schedule status: {}, Created: {} minutes ago'.format(status, created_diff))\n",
    "        if status in ['Completed', 'CompletedWithViolations']:\n",
    "            processing_job_arn = mon['ProcessingJobArn']\n",
    "            break\n",
    "        if status == 'InProgress':\n",
    "            break\n",
    "    else:\n",
    "        raise(Exception('Please wait.  No Schedules executing'))\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View monitoring results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if processing_job_arn:\n",
    "    execution = MonitoringExecution.from_processing_arn(sagemaker_session=sagemaker.Session(),\n",
    "                                                        processing_job_arn=processing_job_arn)\n",
    "    exec_inputs = {inp['InputName']: inp for inp in execution.describe()['ProcessingInputs']}\n",
    "    exec_results_uri = execution.output.destination\n",
    "\n",
    "    print('Monitoring Execution results: {}'.format(exec_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $exec_results_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the baseline and monitoring statistics & violations\n",
    "baseline_statistics = baseline_job.baseline_statistics().body_dict\n",
    "execution_statistics = execution.statistics().body_dict\n",
    "violations = execution.constraint_violations().body_dict['violations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_violation_df(baseline_statistics=baseline_statistics, \n",
    "                     latest_statistics=execution_statistics, \n",
    "                     violations=violations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Define the metric name and threshold\n",
    "metric_name = 'feature_baseline_drift_total_amount'\n",
    "metric_threshold = 0.2\n",
    "\n",
    "# Put a new metric to trigger an alaram\n",
    "def put_drift_metric(value):\n",
    "    print('Putting metric: {}'.format(value))\n",
    "    response = cloudwatch.put_metric_data(\n",
    "        Namespace='aws/sagemaker/Endpoints/data-metrics',\n",
    "        MetricData=[\n",
    "            {\n",
    "                'MetricName': metric_name,\n",
    "                'Dimensions': [\n",
    "                    {\n",
    "                        'Name': 'MonitoringSchedule',\n",
    "                        'Value': schedule_name\n",
    "                    },\n",
    "                    {\n",
    "                        'Name': 'Endpoint',\n",
    "                        'Value': prd_endpoint_name\n",
    "                    },\n",
    "                ],\n",
    "                'Timestamp': datetime.now(),\n",
    "                'Value': value,\n",
    "                'Unit': 'None'\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "def get_drift_stats():\n",
    "    response = cloudwatch.get_metric_statistics(\n",
    "        Namespace='aws/sagemaker/Endpoints/data-metrics',\n",
    "        MetricName=metric_name,\n",
    "        Dimensions=[\n",
    "            {\n",
    "                'Name': 'MonitoringSchedule',\n",
    "                'Value': schedule_name\n",
    "            },\n",
    "            {\n",
    "                'Name': 'Endpoint',\n",
    "                'Value': prd_endpoint_name\n",
    "            },\n",
    "        ],\n",
    "        StartTime=datetime.now() - timedelta(minutes=2),\n",
    "        EndTime=datetime.now(),\n",
    "        Period=1,\n",
    "        Statistics=['Average'],\n",
    "        Unit='None'\n",
    "    )\n",
    "    if 'Datapoints' in response and len(response['Datapoints']) > 0:        \n",
    "        return response['Datapoints'][0]['Average']\n",
    "    return 0    \n",
    "\n",
    "print('Simluate drift on endpoint: {}'.format(prd_endpoint_name))\n",
    "\n",
    "while True:\n",
    "    put_drift_metric(round(random.uniform(metric_threshold, 1.0), 4))\n",
    "    drift_stats = get_drift_stats()\n",
    "    print('Average drift amount: {}'.format(get_drift_stats()))\n",
    "    if drift_stats > metric_threshold:\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a html link to the cloudwatch dashboard\n",
    "metric_alarm_name = 'mlops-{}-metric-gt-threshold'.format(model_name)\n",
    "HTML('''<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/cloudwatch/home?region={0}#alarmsV2:alarm/{1}\">CloudWatch Alarm</a> triggers\n",
    "     <a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/codesuite/codepipeline/pipelines/{2}/executions?region={0}\">Code Pipeline Execution</a>'''.format(region, metric_alarm_name, pipeline_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un dashboard en CloudWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = boto3.client('sts')\n",
    "account_id = sts.get_caller_identity().get('Account')\n",
    "dashboard_name = 'mlops-{}'.format(model_name)\n",
    "\n",
    "with open('dashboard.json') as f:\n",
    "    dashboard_body = Template(f.read()).substitute(region=region, account_id=account_id, model_name=model_name)\n",
    "    response = cloudwatch.put_dashboard(\n",
    "        DashboardName=dashboard_name,\n",
    "        DashboardBody=dashboard_body\n",
    "    )\n",
    "\n",
    "# Output a html link to the cloudwatch dashboard\n",
    "HTML('<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/cloudwatch/home?region={0}#dashboards:name={1}\">CloudWatch Dashboard</a>'.format(region, canary_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar el otro notebook de este repositorio [workflow.ipynb](workflow.ipynb) para implementar su propio modelo de ML y desplegarlo como parte de esta pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Ejecute la siguiente celda para eliminar los stacks creados en el pipeline. Para un nombre de modelo de **nyctaxi**, estos serían:\n",
    "\n",
    "1. *nyctaxi*-deploy-prd\n",
    "2. *nyctaxi*-deploy-dev\n",
    "3. *nyctaxi*-workflow\n",
    "4. sagemaker-custom-resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "# Delete the prod and then dev stack\n",
    "for stack_name in [f'{pipeline_name}-deploy-prd', \n",
    "                   f'{pipeline_name}-deploy-dev',\n",
    "                   f'{pipeline_name}-workflow',\n",
    "                   'sagemaker-custom-resource']:\n",
    "    print('Deleting stack: {}'.format(stack_name))\n",
    "    cfn.delete_stack(StackName=stack_name)\n",
    "    cfn.get_waiter('stack_delete_complete').wait(StackName=stack_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código eliminará el dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudwatch.delete_dashboards(DashboardNames=[dashboard_name])\n",
    "print(\"Dashboard deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, cerramos este notebook y podremos eliminar el CloudFormation que creamos para iniciar esta demo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
